---
title: "Observe-ACS"
author: | 
        | christoph.reich@med.uni-heidelberg.de 
        | evangelos.giannitsis@med.uni-heidelberg.de
        | Klinik für Kardiologie, Angiologie und Pneumologie
        | Universitätsklinikum Heidelberg
        | 
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    df_print: kable
---


```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(
  echo = FALSE)
```

```{r dependencies, include=FALSE}
library(readxl)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(tableone)
library(skimr)
library(mice)  # for missing data
library(VIM)  # for missing data
library(caret)  # for modelling
library(tictoc)
library(pROC)
library(glmnet)
library(survival)
library(survminer)
library(ggsci)
library(lubridate)

# define mode function (will be needed later)  !!!
mode <- function(x, na.rm = FALSE) {
  if(na.rm){
    x = x[!is.na(x)]
  }

  ux <- unique(x)
  return(ux[which.max(tabulate(match(x, ux)))])
}
```


```{r read-data, echo=FALSE}
base::source("scripts/data_preprocessing.R")
```

![AG Meder](../../img/meder_presentation_heart.png)

# Data description

The data set consists of `r nrow(dat.observe)` patients. There are `r ncol(dat.observe)` variables in our data set.
`r round(100*(sum(is.na(dat.observe)) / ncol(dat.observe) / nrow(dat.observe)), 1)`\% of the 
values are missing.

# Demographics

## EDA 

First we want to describe our *ObserveACS*-cohort and get an impression of the variable's distribution: 

```{r EDA, echo=FALSE}
# skim
skimr::skim(data=dat.observe)

# vector of nonnormal vars
## nonnormal <-  c("ntproBNP", "Trop", "Kreatinin", "Triglycerides", "LGE")
```


### inspect some distributions

* age

```{r inspect-age-distr, echo=FALSE, fig.show="hold", out.width="50%"}
ggplot2::ggplot(data=dat.observe, aes(x=V_age))+
  geom_histogram(colour="black", fill="white", bins = 30)+
  xlab("Age")+
  ylab("Count")+
  theme_bw()

ggplot2::ggplot(data=dat.observe, aes(x=V_age))+
  geom_histogram(aes(y=..density..), colour="black", fill="white", bins = 30)+
    geom_density(alpha=0.2, fill="#FF6666")+
  xlab("Age")+
  ylab("Density")+
  theme_bw()
```

* copeptin

```{r inspect-copeptin-distr, echo=FALSE, fig.show="hold", out.width="50%"}
ggplot2::ggplot(data=dat.observe, aes(x=COPEPTIN_COMBINED))+
  geom_histogram(colour="black", fill="white", bins = 30, na.rm = TRUE)+
  xlab("Copeptin")+
  ylab("Count")+
  theme_bw()

ggplot2::ggplot(data=dat.observe, aes(x=COPEPTIN_COMBINED))+
  geom_histogram(aes(y=..density..), colour="black", fill="white", bins = 30, na.rm=TRUE)+
  geom_density(alpha=0.2, fill="#FF6666", na.rm=TRUE)+
  xlab("Copeptin")+
  ylab("Density")+
  theme_bw()
```

### inspect all numeric vars' distributions

```{r loop-numeric-cols-for-distr, echo=FALSE, fig.show="hold", out.width="50%"}
colNames <- names(dat.observe_numeric)[2:47]

# drop cat cars from numerical vars
index <- names(dat.observe_numeric) %in% catVars
dat.observe_numeric <- dat.observe_numeric[ , !index]

for(i in colNames){
  plt <- ggplot(dat.observe_numeric, aes_string(x=i)) +
    geom_histogram(aes(y=..density..), 
                   colour="black", fill="white", bins = 30, na.rm=TRUE)+
    geom_density(alpha=0.2, fill="#FF6666", na.rm = TRUE)+
    xlab(i)+
    ylab("Density")+
    theme_bw()
  print(plt)
  # Sys.sleep(2) # time to inspect plot
}
```

We can clearly observe that not all vars follow a Gaussian distribution. We might
consider this in our descriptive stats. So we create a vector ob clearly non-normal
features: 

```{r nonnormality-check-for-descriptive-stats, echo=FALSE}
# vector of nonnormal vars
#sunonnormal <-  c("ntproBNP", "Trop", "Kreatinin", "Triglycerides", "LGE")

```

\clearpage

# Missing values

## Inspect missing values

Here we inspect missing values. Later we deal with missing values with the `MICE` approach. First we calculate which cols are missing more than 30% data: 

```{r investigate-NA, echo=FALSE}
# show vals that have > 30% missing data
pMiss_observe <- apply(dat.observe,2,pMiss)
index <- pMiss_observe > 30
round(pMiss_observe[index], 2)
```

We can conclude that some vals are just missing because they were not existing (e.g., `V_ekg_st_hebung`
`V_ekg_schenkelblock`, `V_o_stroke`, `V_o_time_stroke`, ...). Therefore, we go on and add `0` for some vars
where we can be quite sure (done in script **data_preprocessing.R** and stored in `dat`).


## Plot missing data

```{r plot-missing-NA, echo=FALSE}
# md.pattern(dat.observe, plot=FALSE)

dat.observe_numeric %>% select(-V_rapID) %>% 
  select(1:10) %>% 
  mice::md.pattern(.)

aggr_plot_demo <- VIM::aggr(dat.observe[demographics_cat], 
                           col=c('navyblue','red'), 
                           numbers=TRUE, 
                           sortVars=TRUE, 
                           labels=substring(names(dat.observe[demographics_cat]), 5),
                           cex.axis=.7, gap=3, 
                           ylab=c("Histogram of missing data","Pattern"),
                           combined=FALSE
)

aggr_plot_ecg <- VIM::aggr(dat.observe[ecg_cat], 
                       col=c('navyblue','red'), 
                       numbers=TRUE, 
                       sortVars=TRUE, 
                       labels=substring(names(dat.observe[ecg_cat]), 7),
                       cex.axis=.7, gap=3, 
                       ylab=c("Histogram of missing data","Pattern"),
                       combined=FALSE
)

aggr_plot_outcomes <- VIM::aggr(dat.observe[outcomes_cat], 
                           col=c('navyblue','red'), 
                           numbers=TRUE, 
                           sortVars=TRUE, 
                           labels=substring(names(dat.observe[outcomes_cat]), 2),
                           cex.axis=.7, gap=3, 
                           ylab=c("Histogram of missing data","Pattern"),
                           combined=FALSE
)

aggr_plot_scores <- VIM::aggr(dat.observe[scores_cat], 
                                col=c('navyblue','red'), 
                                numbers=TRUE, 
                                sortVars=TRUE, 
                                labels=substring(names(dat.observe[scores_cat]), 10),
                                cex.axis=.7, gap=3, 
                                ylab=c("Histogram of missing data","Pattern"),
                                combined=FALSE
)

```

## Drop cols missing more >30% data

```{r reinvestigate-NA-after-edit, echo=FALSE}
# edit NA values (also done in preprocessing and stored in 'dat'), here again to show what was done
dat.observe %>%
  # replace_na works with "specified values" only
  tidyr::replace_na(
    list(
      V_ekg_st_hebung = 0,
      V_ekg_schenkelblock = 0,
      V_o_stroke = 0,
      V_o_cabg=0,
      V_o_reinfarction=0,
      V_o_recoro=0,
      V_o_re_ptca =0,
      # # we also have to edit the outcome data and assume that patients where NA is observed in mortality -> no mortality
      V_mortality_30d = 0,
      V_mortality_90d=0,
      V_o_mortality=0,
      V_aufnahme_krankenhaus=0
    )
  ) %>% 
  # to replace with values from column we use mutate and ifelse
  # here we can add time until death as those patients definitely were not
  # observed longer and would not be counted as stroke
  mutate(
    V_o_time_stroke = ifelse(is.na(V_o_time_stroke),V_o_time_mortality, V_o_time_stroke),
    V_o_time_cabg = ifelse(is.na(V_o_time_cabg),V_o_time_mortality, V_o_time_cabg),
    V_o_time_reinfarction = ifelse(is.na(V_o_time_reinfarction),V_o_time_mortality, V_o_time_reinfarction),
    V_o_time_recoro = ifelse(is.na(V_o_time_recoro),V_o_time_mortality, V_o_time_recoro),
    V_o_time_re_ptca = ifelse(is.na(V_o_time_re_ptca),V_o_time_mortality, V_o_time_re_ptca)
  ) -> dat.observe

pMiss_observe <- apply(dat.observe,2,pMiss)
index <- pMiss_observe > 30
```

Now we continue and drop cols with missing > 30% data (containing at least 70%; done in `data_preprocessing.R`
and stored in `dat`). Those are the following cols (n=`r sum(index)`): <br/>

`r kableExtra::kable(names(pMiss_observe[index]))`


# Data description after NA edit

The data set consists of `r nrow(dat)` patients. 
After removing variables with too many missing values, 
`r ncol(dat)` variables remain in the data set.
Now, `r round(100*(sum(is.na(dat)) / ncol(dat) / nrow(dat)), 1)`\% of the 
values are missing.

\clearpage


# MICE Imputation

## Predictor Matrix

We use the mice package for multiple imputation.  
*CAVE*: If there are too many factor levels -> `mice` automatically converts factors 
(categorical variables) to dummy variables, each level is modeled by its own imputation mode! <br /> 

The default methods are:

- `pmm`: predictive mean matching for numeric and integer data
- `logreg`: log regression for binary data 
- `polyreg`: polytomous regression imputation for un- ordered categorical data (factor > 2 levels)
- `polr`: POM for orderd, > 2 levels

```{r separate-outcomes-from-dat, echo=FALSE}
# dat was created in data_preprocessing

# dat.outcome

# dat.independent
```

We created a separate dataframe only consisting of `r ncol(dat.independent)` independent predictor vars, 
on which we are going to perform multiple imputation. First, we define which vars we do not want to 
include in our `predictorMatrix` for multiple imputation (remove vars as mice predictors). We can also
define vars we want to exclude from imputation. Since we have already separated the **outcomes dataframe**, 
we can carry on without trouble ;)

```{r set-imp-vals, echo=FALSE}
set.seed(123)
# no of imputations
m <- 5

# initiate matrices --------------------------------------------------------
init = mice(dat.independent, maxit=0) 
meth = init$method
predM = init$predictorMatrix

# remove variables as predictors -------------------------------------------
predM[, c("V_rapID", "V_admission_month", "V_admission_week","V_admission_weekday","V_admission_hour","V_symptombeginn","V_symptom_thoraxschmerz","V_symptomtyp","V_h_vessel_disease","V_h_lvdys_grad","V_ekg_t_negativierung","V_ekg_schrittmacher","V_ekg_atriale_tachy","V_ekg_block_ohne_sm", "V_ekg_st_senkung",
          "V_ekg_sinusrhythmus","V_ekg_sinus_normal","KHK__Killip_Class")] = 0

# skip var from imputation -----------------------------------------------
# meth[c("Age")]=""

# specify alternative method ----------------------------------------------
# meth[c("Cholesterol")]="norm" 
# meth[c("Education")]="polr"  # POM model

# logged events -----------------------------------
head(init$loggedEvents, 2)

```

We receive warning on **logged events**: mice found some peculiarities in the data that need the user’s attention. The logged events form a structured report that identify problems with the data, and details which corrective actions were taken by mice(). It is a component called loggedEvents of the mids object. A constant variable is removed from the imputation model (unless the `remove.constant=FALSE` argument is specified); a variable that is collinear with another variable is removed from the imputation model, unless the `remove.collinear=FALSE` argument is specified. 

Categorical vars are internally represented as dummy vars, so the actual number of predictors can easily explode! This makes the algorithm slow, if it runs at all.

```{r inspectNAagain, echo=FALSE}
table(init$nmis)  # 26 vars are complete
```

We can see that `r table(init$nmis)[1]` vars are complete.

## Imputation Process

Now it is time to run the multiple (m=`r m`) imputation.

```{r imputation, include=FALSE}
library(tictoc)
tictoc::tic()
# run the multiple imputation:
imputed <- mice::mice(dat.independent, 
                     m = m,  # no of multiple imputations
                     method = meth,  
                     predictorMatrix = predM,  # specifying the set of predictors to be used for each target column
                     printFlag = F,  # for silent computation
                     seed = 2022)

tictoc::toc()  # for m=5 ~37.827 sec elapsed

# Create a dataset after imputation:
complete(imputed, 
         action="long",  # m imputed datasets 
         include = FALSE
         )  %>%
  # check logged events again (would be excluded if collinearity occurs) https://stefvanbuuren.name/fimd/sec-toomany.html
  select(-c(imputed$loggedEvents$out[imputed$loggedEvents$meth == "collinear"])) %>%
  # check that no more missing vars are in the data
  select_if(~sum(is.na(.)) == 0)  -> impdat
```


## Inspect imputation

Inspect the trace lines: 

```{r plot-trace, cache=TRUE, echo=FALSE}
plot(imputed)
stripplot(imputed)
```


# Correlation of predictor vars

E.g. we can look at systolic and diastolic blood pressure:

```{r correlation, echo=FALSE}
# blood pressure 
cor(dat.independent$V_vit_rr_syst, y=dat.independent$V_vit_rr_diast, use="complete.obs")

## ALL numeric Vars ----------------------------------------------------------
# only numeric vars for correlation
numcols <- unlist(lapply(impdat, is.numeric))
cordat <- impdat[numcols][4:33]
# calculate correlation matrix
correlationMatrix <- cor(x=cordat, method = "pearson")
highCorr <- sum(abs(correlationMatrix[base::upper.tri(correlationMatrix)]) > .75)  # 5 vars can later be dropped
summary(correlationMatrix[upper.tri(correlationMatrix)])

# find attributes that are highly corrected (ideally >0.75) -------------------
highlyCorrelated <- caret::findCorrelation(correlationMatrix, cutoff=0.75, verbose=TRUE,
                                           #names=TRUE, 
                                           exact = TRUE) 
# Generally, you want to remove attributes with an absolute correlation of 0.75 or higher.
# print indexes of highly correlated attributes 
print(highlyCorrelated)
# names of highly correlated features in "cordat" (correlationMatrix is matrix -> no names) -----
colnames(cordat)[highlyCorrelated]  # e.g., ck correlated with krea 

# FIND OUT which vars are correlated? -> look at output (verbose=TRUE) of findCorrelation
## 1) "Compare row 10  and column  11 with corr  0.808";   
colnames(cordat)[10:11]  # ckdepi V_t0_krea
# 2) Compare row 22  and column  23 with corr  0.964
colnames(cordat)[22:23]  # Hb und Hämatokrit
# 3) Compare row 28  and column  29 with corr  0.761 
colnames(cordat)[28:29]  # "V_t0_quick_value" "V_t0_inr_value"
# 4) Compare row 24  and column  25 with corr  0.863
colnames(cordat)[24:25]  # "V_t0_mcv_value" "V_t0_mch_value"
# 5) Compare row 20  and column  21 with corr  0.785
colnames(cordat)[20:21]  # ""V_t0_got_value" "V_t0_gpt_value"

# plot heatmap - for ggcorr and corrplot too many features
heatmap(x = correlationMatrix, symm = TRUE)
```

## High Correlation plots

```{r plot-high-cor-features, echo=FALSE}
library(PerformanceAnalytics)
my_data <- cordat[c(10:11, 22:23, 28:29, 24:25, 20:21)]
PerformanceAnalytics::chart.Correlation(my_data, histogram=TRUE, pch=19)

library(GGally)
GGally::ggpairs(my_data, title="correlogram") 
```

\clearpage


# Feature Selection

## Elastic Net

We have to do variable selection for each imputed dataset separately!!!!!
For **each** dataset, we search the optimal elastic net penalty parameters
($\alpha$ and $\lambda$) via grid search.

### Overall Mortality

From `nrow(dat)` patients in our *Observe-ACS* cohort we observed overall mortality in `r sum(dat.outcome$V_o_mortality==1)` patients whereas `r sum(dat.outcome$V_o_mortality==0)` survived. 

```{r elastic-net-overall-mortality, echo=FALSE}

set.seed(20220106)
# for cross-validation
K=5

# impdat %>%
#   # only interested in pat without Afib, since that is an indication for NOAC per se
#   filter(basis_afib == "0") %>%
#   # drop column, since no information (only zeros)
#   select(-basis_afib) -> dat2

ctrl <- caret::trainControl(method = "cv",
                     number = K,  
                     classProbs = T,
                     summaryFunction = caret::twoClassSummary)

enet_grid <- expand.grid(alpha = seq(0.1, 0.9, 0.1),
                         lambda = c(0.1, 0.2, 0.5))

# create matrix to store beta values with nrow=m, and ncol=ncol(independent_data)+auc
beta_overall <- matrix(nrow = m, ncol = ncol(impdat) - 2)  # we do not need .imp, .id, V_rapID in our matrix (but we will add "Best_AUC")
colnames(beta_overall) <- c(names(impdat[,-c(1,2,3)]), "Best_AUC")

# iterate over all multiple imputed datasets 1:m ---------------------------
tictoc::tic()
for(i in 1:m) {
  ## independent data "X"
  impdat %>% 
    dplyr::filter(.imp == i) %>%  # filter imputed dataset 
    # drop unnecessary cols (decide what we want to model)
    dplyr::select(-c(.id, .imp, V_rapID)) %>% 
    # convert to data.matrix necessary for caret
    base::data.matrix(.) %>% 
    # scale data
    base::scale(x=., center=TRUE, scale=TRUE) -> X
          # .imp An optional column number or column name in long, indicating the imputation
          # index. The values are assumed to be consecutive integers between 0 and m.
          # Values 1 through m correspond to the imputation index, value 0 indicates the
          # original data (with missings). By default, the procedure will search for a variable
          # named ".imp".
  
  ## target data "y"
  dat.outcome %>% 
    # we do not have multiple imputed outcome data (no need to filter(.imp == i))
    select(V_o_mortality) %>%
    # unlist needed for caret
    unlist %>%
    # rename factor labels
    factor(., labels = c("no", "yes")) -> y
  
  plr1 <- caret::train(x=X, 
                       y=y, 
                       method = "glmnet", 
                       metric = "ROC", 
                       tuneGrid = enet_grid,
                       trControl = ctrl)
  
  net1 <- glmnet(X, 
                 as.factor(y),
                 family = "binomial",
                 alpha = plr1$bestTune$alpha, # tune!
                 lambda = plr1$bestTune$lambda) # tune!
  
  beta_overall[i, ] <- c(as.numeric(net1$beta), max(plr1$results$ROC))
}
tictoc::toc()

# add mean of all imputation values, min, max and colSums where beta !=0
beta_overall <- rbind(beta_overall,  # beta values (for m imputations m rows)
              colMeans(beta_overall),  # mean of beta values across imputations
              apply(beta_overall, 2, min),  # min beta across imputations
              apply(beta_overall, 2, max),  # max beta across imputations
              colSums(beta_overall != 0)  # how often was feature chosen? so where is beta not null and sumup
              )

beta_overall <- base::t(beta_overall)  # matrix transpose
# order matrix based on how hoften betas were calculated
index <- rev(
  order(  # Ordering Permutation -> returns index
    beta_overall[,ncol(beta_overall)]  # order based on last col of beta (which is how often a feature was chosen (has beta values))
    )
  )
# order beta matrix
beta_overall <- beta_overall[index,]
# delete all the beta estimates based on one imputation only
beta_overall <- beta_overall[,-(1:m)]
colnames(beta_overall) <- c("Mean Estimate", "Minimum", "Maximum", "Selection Count") # count how often each feature was selected in imputed datasets 
```

We calculate our estimates based on `r length(unique(impdat$.id))` patients in the ACS observe zone.  

We obtain

```{r beta-overall-mortality, echo=FALSE}
round(beta_overall, 2)
```


### 90-day mortality

From `nrow(dat)` patients in our *Observe-ACS* cohort we observed overall mortality in `r sum(dat.outcome$V_mortality_90d==1)` patients whereas `r sum(dat.outcome$V_mortality_90d==0)` survived. In overall mortality we observed `r sum(dat.outcome$V_mortality_90d==1)`, so our number of events has more than halved. Let's see what we get: 

```{r elastic-net-90d-mortality, echo=FALSE}

set.seed(20220106)
# for cross-validation
K=5

# impdat %>%
#   # only interested in pat without Afib, since that is an indication for NOAC per se
#   filter(basis_afib == "0") %>%
#   # drop column, since no information (only zeros)
#   select(-basis_afib) -> dat2

ctrl <- caret::trainControl(method = "cv",
                     number = K,  
                     classProbs = T,
                     summaryFunction = caret::twoClassSummary)

enet_grid <- expand.grid(alpha = seq(0.1, 0.9, 0.1),
                         lambda = c(0.1, 0.2, 0.5))

# create matrix to store beta values with nrow=m, and ncol=ncol(independent_data)+auc
beta_90 <- matrix(nrow = m, ncol = ncol(impdat) - 2)  # we do not need .imp, .id, V_rapID in our matrix (but we will add "Best_AUC")
colnames(beta_90) <- c(names(impdat[,-c(1,2,3)]), "Best_AUC")

# iterate over all multiple imputed datasets 1:m ---------------------------
tictoc::tic()
for(i in 1:m) {
  ## independent data "X"
  impdat %>% 
    dplyr::filter(.imp == i) %>%  # filter imputed dataset 
    # drop unnecessary cols (decide what we want to model)
    dplyr::select(-c(.id, .imp, V_rapID)) %>% 
    # convert to data.matrix necessary for caret
    base::data.matrix(.) %>% 
    # scale data
    base::scale(x=., center=TRUE, scale=TRUE) -> X
          # .imp An optional column number or column name in long, indicating the imputation
          # index. The values are assumed to be consecutive integers between 0 and m.
          # Values 1 through m correspond to the imputation index, value 0 indicates the
          # original data (with missings). By default, the procedure will search for a variable
          # named ".imp".
  ## target data "y"
  dat.outcome %>% 
    # we do not have multiple imputed outcome data (no need to filter(.imp == i))
    select(V_mortality_90d) %>%
    # unlist needed for caret
    unlist %>%
    # rename factor labels
    factor(., labels = c("no", "yes")) -> y
  
  plr1 <- caret::train(x=X, 
                       y=y, 
                       method = "glmnet", 
                       metric = "ROC", 
                       tuneGrid = enet_grid,
                       trControl = ctrl)
  
  net1 <- glmnet(X, 
                 as.factor(y),
                 family = "binomial",
                 alpha = plr1$bestTune$alpha, # tune!
                 lambda = plr1$bestTune$lambda) # tune!
  
  beta_90[i, ] <- c(as.numeric(net1$beta), max(plr1$results$ROC))
}
tictoc::toc()

# add mean of all imputation values, min, max and colSums where beta !=0
beta_90 <- rbind(beta_90,  # beta values (for m imputations m rows)
              colMeans(beta_90),  # mean of beta values across imputations
              apply(beta_90, 2, min),  # min beta across imputations
              apply(beta_90, 2, max),  # max beta across imputations
              colSums(beta_90 != 0)  # how often was feature chosen? so where is beta not null and sumup
              )

beta_90 <- base::t(beta_90)  # matrix transpose
# order matrix based on how hoften betas were calculated
index <- rev(
  order(  # Ordering Permutation -> returns index
    beta_90[,ncol(beta_90)]  # order based on last col of beta (which is how often a feature was chosen (has beta values))
    )
  )
# order beta matrix
beta_90 <- beta_90[index,]
# delete all the beta estimates based on one imputation only
beta_90 <- beta_90[,-(1:m)]
colnames(beta_90) <- c("Mean Estimate", "Minimum", "Maximum", "Selection Count") # count how often each feature was selected in imputed datasets 
```

We calculate our estimates based on `r length(unique(impdat$.id))` patients in the ACS observe zone.  

We obtain

```{r beta-90d-mortality, echo=FALSE}
round(beta_90, 2)
```


### 30-day mortality

From `nrow(dat)` patients in our *Observe-ACS* cohort we observed overall mortality in `r sum(dat.outcome$V_mortality_30d==1)` patients whereas `r sum(dat.outcome$V_mortality_30d==0)` survived. So we really have only a few events in that short 30-day period... 

```{r elastic-net-30d-mortality, echo=FALSE, warning=FALSE}

set.seed(20220106)
# for cross-validation
K=5

# impdat %>%
#   # only interested in pat without Afib, since that is an indication for NOAC per se
#   filter(basis_afib == "0") %>%
#   # drop column, since no information (only zeros)
#   select(-basis_afib) -> dat2

ctrl <- caret::trainControl(method = "cv",
                     number = K,  
                     classProbs = T,
                     summaryFunction = caret::twoClassSummary)

enet_grid <- expand.grid(alpha = seq(0.1, 0.9, 0.1),
                         lambda = c(0.1, 0.2, 0.5))

# create matrix to store beta values with nrow=m, and ncol=ncol(independent_data)+auc
beta_30 <- matrix(nrow = m, ncol = ncol(impdat) - 2)  # we do not need .imp, .id, V_rapID in our matrix (but we will add "Best_AUC")
colnames(beta_30) <- c(names(impdat[,-c(1,2,3)]), "Best_AUC")

# iterate over all multiple imputed datasets 1:m ---------------------------
tictoc::tic()
for(i in 1:m) {
  ## independent data "X"
  impdat %>% 
    dplyr::filter(.imp == i) %>%  # filter imputed dataset 
    # drop unnecessary cols (decide what we want to model)
    dplyr::select(-c(.id, .imp, V_rapID)) %>% 
    # convert to data.matrix necessary for caret
    base::data.matrix(.) %>% 
    # scale data
    base::scale(x=., center=TRUE, scale=TRUE) -> X
          # .imp An optional column number or column name in long, indicating the imputation
          # index. The values are assumed to be consecutive integers between 0 and m.
          # Values 1 through m correspond to the imputation index, value 0 indicates the
          # original data (with missings). By default, the procedure will search for a variable
          # named ".imp".
  
  ## target data "y"
  dat.outcome %>% 
    # we do not have multiple imputed outcome data (no need to filter(.imp == i))
    select(V_mortality_30d) %>%
    # unlist needed for caret
    unlist %>%
    # rename factor labels
    factor(., labels = c("no", "yes")) -> y
  
  plr1 <- caret::train(x=X, 
                       y=y, 
                       method = "glmnet", 
                       metric = "ROC", 
                       tuneGrid = enet_grid,
                       trControl = ctrl)
  
  net1 <- glmnet(X, 
                 as.factor(y),
                 family = "binomial",
                 alpha = plr1$bestTune$alpha, # tune!
                 lambda = plr1$bestTune$lambda) # tune!
  
  beta_30[i, ] <- c(as.numeric(net1$beta), max(plr1$results$ROC))
}
tictoc::toc()

# add mean of all imputation values, min, max and colSums where beta !=0
beta_30 <- rbind(beta_30,  # beta values (for m imputations m rows)
              colMeans(beta_30),  # mean of beta values across imputations
              apply(beta_30, 2, min),  # min beta across imputations
              apply(beta_30, 2, max),  # max beta across imputations
              colSums(beta_30 != 0)  # how often was feature chosen? so where is beta not null and sumup
              )

beta_30 <- base::t(beta_30)  # matrix transpose
# order matrix based on how hoften betas were calculated
index <- rev(
  order(  # Ordering Permutation -> returns index
    beta_30[,ncol(beta_30)]  # order based on last col of beta (which is how often a feature was chosen (has beta values))
    )
  )
# order beta matrix
beta_30 <- beta_30[index,]
# delete all the beta estimates based on one imputation only
beta_30 <- beta_30[,-(1:m)]
colnames(beta_30) <- c("Mean Estimate", "Minimum", "Maximum", "Selection Count") # count how often each feature was selected in imputed datasets 
```

We calculate our estimates based on `r length(unique(impdat$.id))` patients in the ACS observe zone.  

We obtain

```{r beta-30d-mortality, echo=FALSE}
round(beta_30, 2)
```

\clearpage

# Machine Learning

### Prepare dataset

We use all variables that were selected at least **x** times (we can increase m up to 100 times, but will do that only once).

```{r ml-data, message=FALSE}
# select all vars that were selected over threshold without col "Best_AUC"
inds <- setdiff(
  rownames(beta_overall)[which(beta_overall[,"Selection Count"]>=5)],  # features that were selected over threshold (and AUC which is reported in all imputations..)
  "Best_AUC"
  )

# reduce dataset vars so that only selected features (inds) are used
impdat %>% 
  select(.id, dplyr::all_of(inds)) %>%
  mutate(.id = factor(.id)) -> impdat.ml

# create empty matrix with nrow= no of patients, and ncol= no of selected features
impdat.ml.mean <- matrix(nrow = length(levels(impdat.ml$.id)), ncol = ncol(impdat.ml))
# convert to dataframe
impdat.ml.mean <- data.frame(impdat.ml.mean)
colnames(impdat.ml.mean) <- colnames(impdat.ml)

## dat3 = impdat.ml
##dat4 = impdat.ml.mean

# build "mean/mode" of imputed dataset   (not recommended by developers of mice..)
# CAVE: factors in R -> now factor encoding becomes a bit tricky 0 -> 1, and 1->2 (this is because R stores factors by default with 1 and 2, type `str(categorical_var)` to see how the factor was encoded)
for(i in 1:length(levels(impdat.ml$.id))) {  # 1:961
  impdat.ml %>%
    filter(.id == levels(impdat.ml$.id)[i]) %>%
    select(-.id) -> dummy  # all imputed datasets of one individuum with nrows=m
  impdat.ml.mean[i, 1]  <- levels(impdat.ml$.id)[i]
  impdat.ml.mean[i, -1] <- sapply(dummy, function(x) {
    if (is(x, "numeric")) 
        res <- mean(x)
    else if (is(x, "factor"))
      res <- mode(x)  # factors change here
    else 
      res <- NA
    return(res)
  })
}

# Scale independent data (better performed only on training data...)
impdat.ml.mean %>% 
  select(-.id) %>% 
  data.matrix %>% 
  scale(x=., center=TRUE, scale=TRUE) -> X

## target data "y"
dat.outcome %>%
  # we do not have multiple imputed outcome data (no need to filter(.imp == i))
  select(V_o_mortality) %>%
  # unlist needed for caret
  unlist %>%
  # rename factor labels
  factor(., labels = c("no", "yes")) -> y
```


## Overall Mortality

In the following, we do `r K`-fold cross-validation to appropriately evaluate
the models.

We have `r nrow(X)` patients and `r ncol(X)` variables.
`r sum(y == "yes")` patients had a stroke and `r sum(y == "no")` had not.


### Logistic Regression

```{r logreg, echo=FALSE}
set.seed(2022)

logreg <- caret::train(X, 
                       y, 
                       method = "glm", 
                       metric = "ROC", 
                       trControl = ctrl)
```


We obtain an AUC value of `r logreg$results$ROC`.

## Random Forest

```{r rf}
set.seed(2022)

grid_rf <- expand.grid(mtry = seq(1, ncol(X), 1))

randfor <- caret::train(X, 
                        y, 
                        method = "rf", 
                        metric = "ROC", 
                        tuneGrid = grid_rf,
                        trControl = ctrl)

l <- which.max(randfor$results$ROC)
```

Using a tuning parameter of `mtry = ` `r randfor$results$mtry[l]`, 
we obtain an AUC of `r randfor$results$ROC[l]`.

## Support Vector Machine

```{r svm, message=FALSE}
set.seed(463)

grid_svm <- expand.grid(C = c(.1, 1, 5),
                        sigma = c(.05, .1, .5, 1))

svm_res <- caret::train(X, 
                        y, 
                        method = "svmRadial", 
                        metric = "ROC", 
                        tuneGrid = grid_svm,
                        trControl = ctrl)

l <- which.max(svm_res$results$ROC)
```

With tuning parameters `sigma = ` `r svm_res$results$sigma[l]` and
`C = ` `r svm_res$results$C[l]`, we observe an AUC value of `r svm_res$results$ROC[l]`.


## Naive Bayes

```{r nb, message=FALSE, warning=FALSE}
set.seed(435)

nb_res <- caret::train(X, 
                       y, 
                       method = "nb", 
                       metric = "ROC", 
                       trControl = ctrl)
```

We obtain an AUC value of `r max(nb_res$results$ROC)`.


\clearpage
# ROC Curves


## Logistic Regression

```{r plot-auc-logreg}
library(pROC)
pROC_logreg_overall <- roc(y, predict(logreg, X, type="prob")[,"yes"],
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

sens.ci <- ci.se(pROC_logreg_overall)
plot(sens.ci, type="shape", col="lightblue")

# precision/ recall
library(precrec)  # nice package
precrec_logreg_overall <- precrec::evalmod(scores = predict(logreg, X, type="prob")[,"yes"], 
                                    labels = y,
                                     mode="basic"  # default mode="rocprc"
                                    )
autoplot(precrec_logreg_overall)
```


## RF 

Here, we draw an ROC curve for the random forest.

```{r plot-auc-rf, message=FALSE}
pROC_rf_overall <- roc(y, randfor$finalModel$votes[,"yes"],
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

sens.ci <- ci.se(pROC_rf_overall)
plot(sens.ci, type="shape", col="lightblue")

# precision/ recall
library(precrec)  # nice package
precrec_rf_overall <- precrec::evalmod(scores = randfor$finalModel$votes[,"yes"], 
                                    labels = y,
                                     mode="basic"  # default mode="rocprc"
                                    )
autoplot(precrec_rf_overall)
```

# Model with Copeptin

```{r copeptin-data, echo=FALSE}
index=which(!is.na(dat.observe$COPEPTIN_COMBINED))
# pull complete observations of copeptin + ID from all data (before mice and dropping cols with NA>30%)
copeptin_data <- dat.observe[index, c("V_rapID", "COPEPTIN_COMBINED")]

# indices checked, after mice and mean imputation of all datasets we can again use the same indices to combine data
copeptin_data1 <- impdat.ml.mean[index, ]
# colbind
copeptin_data <- cbind(copeptin_data1, copeptin_data["COPEPTIN_COMBINED"])

# outcome data after imputation
dat.outcome_copeptin <- dat.outcome[index, ]


# FOR FEATURE SELECTION:
## if we want to perform the same feature selection as before, we have to replicate our vector first
mice_index <- c(index)
for (i in seq_along(1:(m-1))) {
  # we imputed m times, therefore we need to concat our vector 
  mice_index <- c(mice_index, index+ nrow(dat.observe)*i)
}

# select copeptin data (m*times)
mice_copeptin <- impdat[mice_index, ]
# since we imputed m*times, we also have to replicate our copeptin vector m times
mice_copeptin["COPEPTIN_COMBINED"] <- rep(copeptin_data$COPEPTIN_COMBINED, m)
```

**Copeptin** on top of cardiac troponin supports safe discharge in patients with chest pain or other symptoms suggestive of ACS under routine conditions with the use of a broad spectrum of local standard POC, conventional and high-sensitivity troponin assays. Here we want to investigate if copeptin increases performance of our prognostic models. Unfortunately, within our `observeACS` cohort **copeptin** was only measured in `r nrow(copeptin_data)` patients. There were 


In those `r nrow(copeptin_data)` patients in our *Observe-ACS* cohort we observed overall mortality in only `r sum(dat.outcome_copeptin$V_o_mortality==1)` patients whereas `r sum(dat.outcome_copeptin$V_o_mortality==0)` survived. The low number of events definitely worsens our predictive possibilities.. 


```{r elastic-net-overall-mortality-with-copeptin, echo=FALSE}
set.seed(20220106)
# for cross-validation
K=5

# impdat %>%
#   # only interested in pat without Afib, since that is an indication for NOAC per se
#   filter(basis_afib == "0") %>%
#   # drop column, since no information (only zeros)
#   select(-basis_afib) -> dat2

ctrl <- caret::trainControl(method = "cv",
                     number = K,  
                     classProbs = T,
                     summaryFunction = caret::twoClassSummary)

enet_grid <- expand.grid(alpha = seq(0.1, 0.9, 0.1),
                         lambda = c(0.1, 0.2, 0.5))

# create matrix to store beta values with nrow=m, and ncol=ncol(independent_data)+auc
beta_overall_copeptin <- matrix(nrow = m, ncol = ncol(mice_copeptin) - 2)  # we do not need .imp, .id, V_rapID in our matrix (but we will add "Best_AUC")
colnames(beta_overall_copeptin) <- c(names(mice_copeptin[,-c(1,2,3)]), "Best_AUC")

# iterate over all multiple imputed datasets 1:m ---------------------------
tictoc::tic()
for(i in 1:m) {
  ## independent data "X"
  mice_copeptin %>% 
    dplyr::filter(.imp == i) %>%  # filter imputed dataset 
    # drop unnecessary cols (decide what we want to model)
    dplyr::select(-c(.id, .imp, V_rapID)) %>% 
    # convert to data.matrix necessary for caret
    base::data.matrix(.) %>% 
    # scale data
    base::scale(x=., center=TRUE, scale=TRUE) -> X
          # .imp An optional column number or column name in long, indicating the imputation
          # index. The values are assumed to be consecutive integers between 0 and m.
          # Values 1 through m correspond to the imputation index, value 0 indicates the
          # original data (with missings). By default, the procedure will search for a variable
          # named ".imp".
  
  ## target data "y"
  dat.outcome_copeptin %>% 
    # we do not have multiple imputed outcome data (no need to filter(.imp == i))
    select(V_o_mortality) %>%
    # unlist needed for caret
    unlist %>%
    # rename factor labels
    factor(., labels = c("no", "yes")) -> y
  
  plr1 <- caret::train(x=X, 
                       y=y, 
                       method = "glmnet", 
                       metric = "ROC", 
                       tuneGrid = enet_grid,
                       trControl = ctrl)
  
  net1 <- glmnet(X, 
                 as.factor(y),
                 family = "binomial",
                 alpha = plr1$bestTune$alpha, # tune!
                 lambda = plr1$bestTune$lambda) # tune!
  
  beta_overall_copeptin[i, ] <- c(as.numeric(net1$beta), max(plr1$results$ROC))
}
tictoc::toc()

# add mean of all imputation values, min, max and colSums where beta !=0
beta_overall_copeptin <- rbind(beta_overall_copeptin,  # beta values (for m imputations m rows)
              colMeans(beta_overall_copeptin),  # mean of beta values across imputations
              apply(beta_overall_copeptin, 2, min),  # min beta across imputations
              apply(beta_overall_copeptin, 2, max),  # max beta across imputations
              colSums(beta_overall_copeptin != 0)  # how often was feature chosen? so where is beta not null and sumup
              )

beta_overall_copeptin <- base::t(beta_overall_copeptin)  # matrix transpose
# order matrix based on how hoften betas were calculated
index <- rev(
  order(  # Ordering Permutation -> returns index
    beta_overall_copeptin[,ncol(beta_overall_copeptin)]  # order based on last col of beta (which is how often a feature was chosen (has beta values))
    )
  )
# order beta matrix
beta_overall_copeptin <- beta_overall_copeptin[index,]
# delete all the beta estimates based on one imputation only
beta_overall_copeptin <- beta_overall_copeptin[,-(1:m)]
colnames(beta_overall_copeptin) <- c("Mean Estimate", "Minimum", "Maximum", "Selection Count") # count how often each feature was selected in imputed datasets 
```


We calculate our estimates based on `r length(unique(mice_copeptin$.id))` patients in the ACS observe zone.  

We obtain

```{r beta-overall-mortality, echo=FALSE}
round(beta_overall_copeptin, 2)
```

## Lasso regression

Sample split p=0.6 for train/test set:

```{r more-classical-stats, echo=FALSE}
library(glmnet)
# lasso regression --------------------------------------------------------
set.seed(2022)
dat.outcome_copeptin %>% 
  # we do not have multiple imputed outcome data (no need to filter(.imp == i))
  select(V_o_mortality) %>%
  # unlist needed for caret
  unlist %>%
  # rename factor labels
  factor(., labels = c("no", "yes")) -> y

# split data
in.train <- createDataPartition(y, p=0.6, list=FALSE)
# look at how many events are in each group..
ytrain <- y[in.train]; summary(factor(ytrain))
ytest <- y[-in.train]; summary(factor(ytest))

# create data to model and drop some cols
modeldat <- tibble::as_tibble(cbind(dat.outcome_copeptin["V_o_mortality"], copeptin_data)) %>% 
  select(-c(.id, V_t0_quick_value, V_t0_hkt_value, V_t0_hb_value, V_t0_ldh_value, V_t0_na_value))

# split data
train.data <- modeldat[as.vector(in.train),]
test.data <- modeldat[-as.vector(in.train),]

# additional data preparation
# Dumy code categorical predictor variables
x <- model.matrix(V_o_mortality~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(train.data$V_o_mortality == "0", 0, 1)

# lasso model

# Find the best lambda using cross-validation
# cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial", nfolds = 3)  # we receive errors here, too little observations

# Fit the final model on the training data
model <- glmnet(x, y, alpha = 1, family = "binomial",
                lambda = 0.054 #cv.lasso$lambda.min   ## here random penalty used
                )
# Display regression coefficients
coef(model)
## Copeptin dropped by lasso regression (can be seen as feature selection)

# Make predictions on the test data
x.test <- model.matrix(V_o_mortality ~., test.data)[,-1]
# get probs
probabilities <- model %>% predict(newx = x.test, type="response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

# Model accuracy
observed.classes <- test.data$V_o_mortality
mean(predicted.classes == observed.classes)

# we cant use accuracy as a measure in that setting --> we need another threshold
library(pROC)
pROC_lasso_copeptin <- roc(observed.classes, probabilities,  # or 1-probabilities
                           smoothed = TRUE,
                           # arguments for ci
                           ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                           # arguments for plot
                           plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                           print.auc=TRUE, show.thres=TRUE)

# precision/ recall
library(precrec)  # nice package
precrec_logreg_overall <- precrec::evalmod(scores = probabilities, 
                                           labels = observed.classes,
                                           mode="basic"  # default mode="rocprc"
)
autoplot(precrec_logreg_overall)
```

As seen above, we do not obtain reasonable results due to little events and a small cohort size. Furthermore, we can see that there were no signs that Copeptin would have been chosen in a model above. <br/>

Now we hit it without train/test split and try some simple logistic regression models (all with copeptin).


```{r more-classical-stats2, echo=FALSE}
#------------------------------------------------#
# logistic regression without training data -------------------------------
#------------------------------------------------#

m.01 <- glm(V_o_mortality~COPEPTIN_COMBINED+V_t0_hstnt_value+KHK__Killip_Class+V_age, data=modeldat, 
                     family = binomial(link="logit")
)

m.02 <- glm(V_o_mortality~COPEPTIN_COMBINED+V_t0_hstnt_value+V_age, data=modeldat, 
            family = binomial(link="logit")
)

m.03 <- glm(V_o_mortality~COPEPTIN_COMBINED+V_age, data=modeldat, 
            family = binomial(link="logit")
)

m.04 <- glm(V_o_mortality~V_age, data=modeldat, 
            family = binomial(link="logit")
)

summary(m.01)
summary(m.02)
summary(m.03)
summary(m.04)

anova(m.01, m.02,  test="Chisq")
anova(m.01, m.03, test="Chisq")

m.01_probabilities <- predict(m.01, newdata = modeldat[-1], type = "response")
m.02_probabilities <- predict(m.02, newdata = modeldat[-1], type = "response")
m.03_probabilities <- predict(m.03, newdata = modeldat[-1], type = "response")
m.04_probabilities <- predict(m.04, newdata = modeldat[-1], type = "response")

ind<-modeldat$V_o_mortality==1
m.03_probabilities[ind]

  library(pROC)
pROC_m.01 <- roc(modeldat$V_o_mortality, m.01_probabilities,  # or 1-probabilities
                           smoothed = TRUE,
                           # arguments for ci
                           ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                           # arguments for plot
                           plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                           print.auc=TRUE, show.thres=TRUE)

pROC_m.02 <- roc(modeldat$V_o_mortality, m.02_probabilities,  # or 1-probabilities
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)

pROC_m.03 <- roc(modeldat$V_o_mortality, m.03_probabilities,  # or 1-probabilities
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)

pROC_m.04 <- roc(modeldat$V_o_mortality, m.04_probabilities,  # or 1-probabilities
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)

```

Regarding our logistic regression models, it seems that all information on overall mortality comes from `age` (with regard to the selected variables above). Next, we will continue to build Survival models where we have additional time2event data for mortality. 

\clearpage


# Software

This analysis was carried out using the statistical software `r base::version$version.string`.

Apart from R's base functionality, the following packages were used: <br/>

```{r software, echo=FALSE}
# or faster with function...
installed.packages()[names(sessionInfo()$otherPkgs), "Version"]
```

